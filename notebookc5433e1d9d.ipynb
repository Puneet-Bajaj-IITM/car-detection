{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bc34fe2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-15T12:12:48.418335Z",
     "iopub.status.busy": "2023-11-15T12:12:48.417818Z",
     "iopub.status.idle": "2023-11-15T12:13:04.825397Z",
     "shell.execute_reply": "2023-11-15T12:13:04.823714Z"
    },
    "papermill": {
     "duration": 16.418591,
     "end_time": "2023-11-15T12:13:04.828615",
     "exception": false,
     "start_time": "2023-11-15T12:12:48.410024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d48aaf1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T12:13:04.841919Z",
     "iopub.status.busy": "2023-11-15T12:13:04.841192Z",
     "iopub.status.idle": "2023-11-15T12:13:04.850068Z",
     "shell.execute_reply": "2023-11-15T12:13:04.848637Z"
    },
    "papermill": {
     "duration": 0.018306,
     "end_time": "2023-11-15T12:13:04.852759",
     "exception": false,
     "start_time": "2023-11-15T12:13:04.834453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json \n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# your api key\n",
    "api_key = {\n",
    "    \"username\":\"puneetbajajiitm\",\n",
    "    \"key\":\"01b9347e9b217c13e7e984273cd0c983\"\n",
    "}\n",
    "\n",
    "# uses pathlib Path\n",
    "kaggle_path = Path('/root/.kaggle')\n",
    "os.makedirs(kaggle_path, exist_ok=True)\n",
    "\n",
    "# opens file and dumps python dict to json object \n",
    "with open (kaggle_path/'kaggle.json', 'w') as handl:\n",
    "    json.dump(api_key,handl)\n",
    "\n",
    "os.chmod(kaggle_path/'kaggle.json', 600)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa6ffbd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T12:13:04.866036Z",
     "iopub.status.busy": "2023-11-15T12:13:04.865595Z",
     "iopub.status.idle": "2023-11-15T12:13:04.881759Z",
     "shell.execute_reply": "2023-11-15T12:13:04.880522Z"
    },
    "papermill": {
     "duration": 0.025927,
     "end_time": "2023-11-15T12:13:04.884318",
     "exception": false,
     "start_time": "2023-11-15T12:13:04.858391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def yolo_head(feats, anchors, num_classes):\n",
    "    \"\"\"Convert final layer features to bounding box parameters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    feats : tensor\n",
    "        Final convolutional layer features.\n",
    "    anchors : array-like\n",
    "        Anchor box widths and heights.\n",
    "    num_classes : int\n",
    "        Number of target classes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    box_xy : tensor\n",
    "        x, y box predictions adjusted by spatial location in conv layer.\n",
    "    box_wh : tensor\n",
    "        w, h box predictions adjusted by anchors and conv spatial resolution.\n",
    "    box_conf : tensor\n",
    "        Probability estimate for whether each box contains any object.\n",
    "    box_class_pred : tensor\n",
    "        Probability distribution estimate for each box over class labels.\n",
    "    \"\"\"\n",
    "    num_anchors = len(anchors)\n",
    "    # Reshape to batch, height, width, num_anchors, box_params.\n",
    "    anchors_tensor = K.reshape(K.variable(anchors), [1, 1, 1, num_anchors, 2])\n",
    "\n",
    "    # Static implementation for fixed models.\n",
    "    # TODO: Remove or add option for static implementation.\n",
    "    # _, conv_height, conv_width, _ = K.int_shape(feats)\n",
    "    # conv_dims = K.variable([conv_width, conv_height])\n",
    "\n",
    "    # Dynamic implementation of conv dims for fully convolutional model.\n",
    "    conv_dims = K.shape(feats)[1:3]  # assuming channels last\n",
    "    # In YOLO the height index is the inner most iteration.\n",
    "    conv_height_index = K.arange(0, stop=conv_dims[0])\n",
    "    conv_width_index = K.arange(0, stop=conv_dims[1])\n",
    "    conv_height_index = K.tile(conv_height_index, [conv_dims[1]])\n",
    "\n",
    "    # TODO: Repeat_elements and tf.split doesn't support dynamic splits.\n",
    "    # conv_width_index = K.repeat_elements(conv_width_index, conv_dims[1], axis=0)\n",
    "    conv_width_index = K.tile(\n",
    "        K.expand_dims(conv_width_index, 0), [conv_dims[0], 1])\n",
    "    conv_width_index = K.flatten(K.transpose(conv_width_index))\n",
    "    conv_index = K.transpose(K.stack([conv_height_index, conv_width_index]))\n",
    "    conv_index = K.reshape(conv_index, [1, conv_dims[0], conv_dims[1], 1, 2])\n",
    "    conv_index = K.cast(conv_index, K.dtype(feats))\n",
    "\n",
    "    feats = K.reshape(\n",
    "        feats, [-1, conv_dims[0], conv_dims[1], num_anchors, num_classes + 5])\n",
    "    conv_dims = K.cast(K.reshape(conv_dims, [1, 1, 1, 1, 2]), K.dtype(feats))\n",
    "\n",
    "    # Static generation of conv_index:\n",
    "    # conv_index = np.array([_ for _ in np.ndindex(conv_width, conv_height)])\n",
    "    # conv_index = conv_index[:, [1, 0]]  # swap columns for YOLO ordering.\n",
    "    # conv_index = K.variable(\n",
    "    #     conv_index.reshape(1, conv_height, conv_width, 1, 2))\n",
    "    # feats = Reshape(\n",
    "    #     (conv_dims[0], conv_dims[1], num_anchors, num_classes + 5))(feats)\n",
    "\n",
    "    box_xy = K.sigmoid(feats[..., :2])\n",
    "    box_wh = K.exp(feats[..., 2:4])\n",
    "    box_confidence = K.sigmoid(feats[..., 4:5])\n",
    "    box_class_probs = K.softmax(feats[..., 5:])\n",
    "\n",
    "    # Adjust preditions to each spatial grid point and anchor size.\n",
    "    # Note: YOLO iterates over height index before width index.\n",
    "    box_xy = (box_xy + conv_index) / conv_dims\n",
    "    box_wh = box_wh * anchors_tensor / conv_dims\n",
    "\n",
    "    return box_xy, box_wh, box_confidence, box_class_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0539dc86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T12:13:04.897182Z",
     "iopub.status.busy": "2023-11-15T12:13:04.896761Z",
     "iopub.status.idle": "2023-11-15T12:13:04.969087Z",
     "shell.execute_reply": "2023-11-15T12:13:04.967912Z"
    },
    "papermill": {
     "duration": 0.08236,
     "end_time": "2023-11-15T12:13:04.972021",
     "exception": false,
     "start_time": "2023-11-15T12:13:04.889661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Draw predicted or ground truth boxes on input image.\"\"\"\n",
    "import imghdr\n",
    "import colorsys\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "def preprocess_image(img_path, model_image_size):\n",
    "    image_type = imghdr.what(img_path)\n",
    "    image = Image.open(img_path)\n",
    "    resized_image = image.resize(tuple(reversed(model_image_size)), Image.BICUBIC)\n",
    "    image_data = np.array(resized_image, dtype='float32')\n",
    "    image_data /= 255.\n",
    "    image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "    return image, image_data\n",
    "\n",
    "def compose(*funcs):\n",
    "    \"\"\"Compose arbitrarily many functions, evaluated left to right.\n",
    "\n",
    "    Reference: https://mathieularose.com/function-composition-in-python/\n",
    "    \"\"\"\n",
    "    # return lambda x: reduce(lambda v, f: f(v), funcs, x)\n",
    "    if funcs:\n",
    "        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)\n",
    "    else:\n",
    "        raise ValueError('Composition of empty sequence not supported.')\n",
    "\n",
    "def read_classes(classes_path):\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "def read_anchors(anchors_path):\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "        anchors = [float(x) for x in anchors.split(',')]\n",
    "        anchors = np.array(anchors).reshape(-1, 2)\n",
    "    return anchors\n",
    "\n",
    "def scale_boxes(boxes, image_shape):\n",
    "    \"\"\" Scales the predicted boxes in order to be drawable on the image\"\"\"\n",
    "    height = float(image_shape[0])\n",
    "    width = float(image_shape[1])\n",
    "    image_dims = K.stack([height, width, height, width])\n",
    "    image_dims = K.reshape(image_dims, [1, 4])\n",
    "    boxes = boxes * image_dims\n",
    "    return boxes\n",
    "\n",
    "def get_colors_for_classes(num_classes):\n",
    "    \"\"\"Return list of random colors for number of classes given.\"\"\"\n",
    "    # Use previously generated colors if num_classes is the same.\n",
    "    if (hasattr(get_colors_for_classes, \"colors\") and\n",
    "            len(get_colors_for_classes.colors) == num_classes):\n",
    "        return get_colors_for_classes.colors\n",
    "\n",
    "    hsv_tuples = [(x / num_classes, 1., 1.) for x in range(num_classes)]\n",
    "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    colors = list(\n",
    "        map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n",
    "            colors))\n",
    "    random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "    random.shuffle(colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "    random.seed(None)  # Reset seed to default.\n",
    "    get_colors_for_classes.colors = colors  # Save colors for future calls.\n",
    "    return colors\n",
    "\n",
    "from PIL import ImageFont, ImageDraw\n",
    "\n",
    "def calculate_text_size(text, font):\n",
    "    temp_image = Image.new('RGB', (1, 1))\n",
    "    temp_draw = ImageDraw.Draw(temp_image)\n",
    "    return temp_draw.textbbox((0, 0), text, font=font)\n",
    "\n",
    "def draw_boxes(image, boxes, box_classes, class_names, scores=None):\n",
    "    font = ImageFont.truetype(\n",
    "        font='font/FiraMono-Medium.otf',\n",
    "        size=int(3e-2 * image.size[1] + 0.5))\n",
    "    thickness = (image.size[0] + image.size[1]) // 300\n",
    "\n",
    "    colors = get_colors_for_classes(len(class_names))\n",
    "\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for i, c in enumerate(box_classes):\n",
    "        box_class = class_names[c]\n",
    "        box = boxes[i]\n",
    "\n",
    "        if scores is not None and i < len(scores):\n",
    "            score = scores[i]\n",
    "            label = '{} {:.2f}'.format(box_class, score)\n",
    "        else:\n",
    "            label = '{}'.format(box_class)\n",
    "\n",
    "        label_size = calculate_text_size(label, font)\n",
    "\n",
    "        top, left, bottom, right = box\n",
    "        top = max(0, int(top + 0.5))\n",
    "        left = max(0, int(left + 0.5))\n",
    "        bottom = min(image.size[1], int(bottom + 0.5))\n",
    "        right = min(image.size[0], int(right + 0.5))\n",
    "\n",
    "        if top - label_size[3] >= 0:\n",
    "            text_origin = (left, top - (label_size[3] - label_size[1]))\n",
    "        else:\n",
    "            text_origin = (left, top + 1)\n",
    "\n",
    "        for j in range(thickness):\n",
    "            draw.rectangle(\n",
    "                [left + j, top + j, right - j, bottom - j],\n",
    "                outline=colors[c]\n",
    "            )\n",
    "        draw.rectangle(\n",
    "            [text_origin, (text_origin[0] + label_size[2], text_origin[1] + label_size[3])],\n",
    "            fill=colors[c]\n",
    "        )\n",
    "        draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "\n",
    "    del draw\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ac40875",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T12:13:04.984760Z",
     "iopub.status.busy": "2023-11-15T12:13:04.984346Z",
     "iopub.status.idle": "2023-11-15T12:13:04.992103Z",
     "shell.execute_reply": "2023-11-15T12:13:04.990689Z"
    },
    "papermill": {
     "duration": 0.017183,
     "end_time": "2023-11-15T12:13:04.994637",
     "exception": false,
     "start_time": "2023-11-15T12:13:04.977454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def yolo_filter_boxes(boxes, box_confidence, box_class_probs, threshold = .6):\n",
    "\n",
    "    box_scores = box_confidence * box_class_probs\n",
    "\n",
    "    box_classes = tf.math.argmax(box_scores, axis=-1)\n",
    "    box_class_scores = tf.math.reduce_max(box_scores, axis=-1)\n",
    "    \n",
    "    filtering_mask = tf.math.greater_equal(tf.cast(box_class_scores, dtype= tf.float32), threshold)\n",
    "    \n",
    "    scores = tf.boolean_mask(box_class_scores, filtering_mask)\n",
    "    boxes = tf.boolean_mask(boxes, filtering_mask)\n",
    "    classes = tf.boolean_mask(box_classes, filtering_mask)\n",
    "    \n",
    "    return scores, boxes, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e6fafdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T12:13:05.009243Z",
     "iopub.status.busy": "2023-11-15T12:13:05.008770Z",
     "iopub.status.idle": "2023-11-15T12:13:05.017552Z",
     "shell.execute_reply": "2023-11-15T12:13:05.016275Z"
    },
    "papermill": {
     "duration": 0.020364,
     "end_time": "2023-11-15T12:13:05.020309",
     "exception": false,
     "start_time": "2023-11-15T12:13:04.999945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def iou(box1, box2):\n",
    "\n",
    "    (box1_x1, box1_y1, box1_x2, box1_y2) = box1\n",
    "    (box2_x1, box2_y1, box2_x2, box2_y2) = box2\n",
    "\n",
    "    xi1 = max(box1_x1, box2_x1)\n",
    "    yi1 = max(box1_y1, box2_y1)\n",
    "    xi2 = min(box1_x2, box2_x2)\n",
    "    yi2 = min(box1_y2, box2_y2)\n",
    "    inter_width = xi2 - xi1\n",
    "    inter_height =  yi2 -yi1\n",
    "    inter_area = max(inter_height, 0) * max(inter_width, 0)\n",
    "    \n",
    "    box1_area = (box1_x2 - box1_x1) * (box1_y2 - box1_y1)\n",
    "   \n",
    "    box2_area = (box2_x2 - box2_x1) * (box2_y2 - box2_y1)\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "   \n",
    "    iou = inter_area / union_area\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e77d86a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T12:13:05.033232Z",
     "iopub.status.busy": "2023-11-15T12:13:05.032789Z",
     "iopub.status.idle": "2023-11-15T12:13:05.040222Z",
     "shell.execute_reply": "2023-11-15T12:13:05.039000Z"
    },
    "papermill": {
     "duration": 0.017124,
     "end_time": "2023-11-15T12:13:05.042866",
     "exception": false,
     "start_time": "2023-11-15T12:13:05.025742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def yolo_non_max_suppression(scores, boxes, classes, max_boxes = 10, iou_threshold = 0.5):\n",
    "    \n",
    "    max_boxes_tensor = tf.Variable(max_boxes, dtype='int32')  \n",
    "\n",
    "    nms_indices = tf.image.non_max_suppression(boxes,scores,max_boxes_tensor,iou_threshold)\n",
    "    \n",
    "    scores = tf.gather(scores, nms_indices)\n",
    "    boxes = tf.gather(boxes, nms_indices)\n",
    "    classes = tf.gather(classes, nms_indices)\n",
    "    \n",
    "    return scores, boxes, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d048c198",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T12:13:05.055782Z",
     "iopub.status.busy": "2023-11-15T12:13:05.055312Z",
     "iopub.status.idle": "2023-11-15T12:13:05.063004Z",
     "shell.execute_reply": "2023-11-15T12:13:05.061597Z"
    },
    "papermill": {
     "duration": 0.017271,
     "end_time": "2023-11-15T12:13:05.065575",
     "exception": false,
     "start_time": "2023-11-15T12:13:05.048304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def yolo_boxes_to_corners(box_xy, box_wh):\n",
    "    \n",
    "    box_mins = box_xy - (box_wh / 2.)\n",
    "    box_maxes = box_xy + (box_wh / 2.)\n",
    "\n",
    "    return tf.keras.backend.concatenate([\n",
    "        box_mins[..., 1:2],  # y_min\n",
    "        box_mins[..., 0:1],  # x_min\n",
    "        box_maxes[..., 1:2],  # y_max\n",
    "        box_maxes[..., 0:1]  # x_max\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35442e47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T12:13:05.078631Z",
     "iopub.status.busy": "2023-11-15T12:13:05.078162Z",
     "iopub.status.idle": "2023-11-15T12:13:05.086456Z",
     "shell.execute_reply": "2023-11-15T12:13:05.085370Z"
    },
    "papermill": {
     "duration": 0.01775,
     "end_time": "2023-11-15T12:13:05.088779",
     "exception": false,
     "start_time": "2023-11-15T12:13:05.071029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def yolo_eval(yolo_outputs, image_shape = (720, 1280), max_boxes=10, score_threshold=.6, iou_threshold=.5):\n",
    "    \n",
    "    box_xy, box_wh, box_confidence, box_class_probs = yolo_outputs\n",
    "    \n",
    "    boxes = yolo_boxes_to_corners(box_xy, box_wh)\n",
    "    \n",
    "    scores, boxes, classes = yolo_filter_boxes(boxes, box_confidence, box_class_probs, threshold = score_threshold)\n",
    "    \n",
    "    boxes = boxes = scale_boxes(boxes, image_shape)\n",
    "    \n",
    "    scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes, max_boxes = max_boxes, iou_threshold = iou_threshold)\n",
    "  \n",
    "    return scores, boxes, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c40b96c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T12:13:05.101367Z",
     "iopub.status.busy": "2023-11-15T12:13:05.100883Z",
     "iopub.status.idle": "2023-11-15T12:13:05.117402Z",
     "shell.execute_reply": "2023-11-15T12:13:05.115988Z"
    },
    "papermill": {
     "duration": 0.026422,
     "end_time": "2023-11-15T12:13:05.120586",
     "exception": false,
     "start_time": "2023-11-15T12:13:05.094164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_names = read_classes(\"/kaggle/input/model-data/coco_classes.txt\")\n",
    "anchors = read_anchors(\"/kaggle/input/yolo-anchors/yolo_anchors.txt\")\n",
    "model_image_size = (608, 608) # Same as yolo_model input layer size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3ae7fbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T12:13:05.133323Z",
     "iopub.status.busy": "2023-11-15T12:13:05.132854Z",
     "iopub.status.idle": "2023-11-15T12:13:12.980138Z",
     "shell.execute_reply": "2023-11-15T12:13:12.978741Z"
    },
    "papermill": {
     "duration": 7.857536,
     "end_time": "2023-11-15T12:13:12.983702",
     "exception": false,
     "start_time": "2023-11-15T12:13:05.126166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/lambda_layer.py:327: UserWarning: yad2k.models.keras_yolo is not loaded, but a Lambda layer uses it. It may cause errors.\n",
      "  function = cls._parse_function_from_config(\n"
     ]
    }
   ],
   "source": [
    "yolo_model = load_model(\"/kaggle/input/kaggle/kaggle/kaggle/model_data/\", compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dc9955",
   "metadata": {
    "papermill": {
     "duration": 0.005362,
     "end_time": "2023-11-15T12:13:12.995287",
     "exception": false,
     "start_time": "2023-11-15T12:13:12.989925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3983178,
     "sourceId": 6936408,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3983330,
     "sourceId": 6936513,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3983340,
     "sourceId": 6936523,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 51677611,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30579,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 31.806152,
   "end_time": "2023-11-15T12:13:15.030907",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-15T12:12:43.224755",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
